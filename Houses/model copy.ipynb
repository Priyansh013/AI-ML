{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries and Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import seaborn as sns\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"test.csv\", usecols=[\"MSSubClass\",\"MSZoning\",\"LotFrontage\",\"LotArea\",\"Street\",\"YearBuilt\",\"LotShape\",\"1stFlrSF\",\"2ndFlrSF\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSSubClass       0\n",
       "MSZoning         4\n",
       "LotFrontage    227\n",
       "LotArea          0\n",
       "Street           0\n",
       "LotShape         0\n",
       "YearBuilt        0\n",
       "1stFlrSF         0\n",
       "2ndFlrSF         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LotFrontage'] = df['LotFrontage'].fillna(df['LotFrontage'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSSubClass     0\n",
       "MSZoning       4\n",
       "LotFrontage    0\n",
       "LotArea        0\n",
       "Street         0\n",
       "LotShape       0\n",
       "YearBuilt      0\n",
       "1stFlrSF       0\n",
       "2ndFlrSF       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MSZoning'] = df['MSZoning'].fillna(df['MSZoning'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSSubClass     0\n",
       "MSZoning       0\n",
       "LotFrontage    0\n",
       "LotArea        0\n",
       "Street         0\n",
       "LotShape       0\n",
       "YearBuilt      0\n",
       "1stFlrSF       0\n",
       "2ndFlrSF       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>1961</td>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>1958</td>\n",
       "      <td>1329</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>1997</td>\n",
       "      <td>928</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9978</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>1998</td>\n",
       "      <td>926</td>\n",
       "      <td>678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120</td>\n",
       "      <td>RL</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5005</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>1992</td>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape  YearBuilt  \\\n",
       "0          20       RH         80.0    11622   Pave      Reg       1961   \n",
       "1          20       RL         81.0    14267   Pave      IR1       1958   \n",
       "2          60       RL         74.0    13830   Pave      IR1       1997   \n",
       "3          60       RL         78.0     9978   Pave      IR1       1998   \n",
       "4         120       RL         43.0     5005   Pave      IR1       1992   \n",
       "\n",
       "   1stFlrSF  2ndFlrSF  \n",
       "0       896         0  \n",
       "1      1329         0  \n",
       "2       928       701  \n",
       "3       926       678  \n",
       "4      1280         0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1459 entries, 0 to 1458\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   MSSubClass   1459 non-null   int64  \n",
      " 1   MSZoning     1459 non-null   object \n",
      " 2   LotFrontage  1459 non-null   float64\n",
      " 3   LotArea      1459 non-null   int64  \n",
      " 4   Street       1459 non-null   object \n",
      " 5   LotShape     1459 non-null   object \n",
      " 6   YearBuilt    1459 non-null   int64  \n",
      " 7   1stFlrSF     1459 non-null   int64  \n",
      " 8   2ndFlrSF     1459 non-null   int64  \n",
      "dtypes: float64(1), int64(5), object(3)\n",
      "memory usage: 102.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Name: MSSubClass and unique values: 16\n",
      "Column Name: MSZoning and unique values: 5\n",
      "Column Name: LotFrontage and unique values: 116\n",
      "Column Name: LotArea and unique values: 1106\n",
      "Column Name: Street and unique values: 2\n",
      "Column Name: LotShape and unique values: 4\n",
      "Column Name: YearBuilt and unique values: 106\n",
      "Column Name: 1stFlrSF and unique values: 789\n",
      "Column Name: 2ndFlrSF and unique values: 407\n"
     ]
    }
   ],
   "source": [
    "for i in df.columns:\n",
    "    print(\"Column Name: {} and unique values: {}\". format(i, len(df[i].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ~All the features that have limited variations in their values have to be converted into categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.datetime.now().year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Total_Years'] = datetime.datetime.now().year - df[\"YearBuilt\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"YearBuilt\",axis = 1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
       "       'LotShape', '1stFlrSF', '2ndFlrSF', 'Total_Years'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>Total_Years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>1329</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>928</td>\n",
       "      <td>701</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9978</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>926</td>\n",
       "      <td>678</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120</td>\n",
       "      <td>RL</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5005</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape  1stFlrSF  \\\n",
       "0          20       RH         80.0    11622   Pave      Reg       896   \n",
       "1          20       RL         81.0    14267   Pave      IR1      1329   \n",
       "2          60       RL         74.0    13830   Pave      IR1       928   \n",
       "3          60       RL         78.0     9978   Pave      IR1       926   \n",
       "4         120       RL         43.0     5005   Pave      IR1      1280   \n",
       "\n",
       "   2ndFlrSF  Total_Years  \n",
       "0         0           63  \n",
       "1         0           66  \n",
       "2       701           27  \n",
       "3       678           26  \n",
       "4         0           32  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ~Applying Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Categorcal Data\n",
    "cat_features = ['MSSubClass', 'MSZoning','Street','LotShape']\n",
    "out_feature = \"SalePrice\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 5, ..., 0, 9, 5])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbl_encoders={} \n",
    "lbl_encoders[\"MSSubClass\"] = LabelEncoder() \n",
    "lbl_encoders[\"MSSubClass\"].fit_transform(df[\"MSSubClass\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_encoders={} \n",
    "for feature in cat_features:\n",
    "    lbl_encoders[feature] = LabelEncoder()\n",
    "    df[feature] = lbl_encoders[feature].fit_transform(df[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>Total_Years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1329</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>928</td>\n",
       "      <td>701</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9978</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>926</td>\n",
       "      <td>678</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5005</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  MSZoning  LotFrontage  LotArea  Street  LotShape  1stFlrSF  \\\n",
       "0           0         2         80.0    11622       1         3       896   \n",
       "1           0         3         81.0    14267       1         0      1329   \n",
       "2           5         3         74.0    13830       1         0       928   \n",
       "3           5         3         78.0     9978       1         0       926   \n",
       "4          11         3         43.0     5005       1         0      1280   \n",
       "\n",
       "   2ndFlrSF  Total_Years  \n",
       "0         0           63  \n",
       "1         0           66  \n",
       "2       701           27  \n",
       "3       678           26  \n",
       "4         0           32  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ~Applying Embedding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2, 1, 3],\n",
       "       [0, 3, 1, 0],\n",
       "       [5, 3, 1, 0],\n",
       "       ...,\n",
       "       [0, 3, 1, 3],\n",
       "       [9, 3, 1, 3],\n",
       "       [5, 3, 1, 3]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Stacking and COnverting into Tensors\n",
    "\n",
    "cat_features = np.stack([df['MSSubClass'], df['MSZoning'],df['Street'] , df['LotShape']] , axis=1)\n",
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 2, 1, 3],\n",
       "        [0, 3, 1, 0],\n",
       "        [5, 3, 1, 0],\n",
       "        ...,\n",
       "        [0, 3, 1, 3],\n",
       "        [9, 3, 1, 3],\n",
       "        [5, 3, 1, 3]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## COnvert numpy arrays to tensors\n",
    "\n",
    "cat_features = torch.tensor(cat_features, dtype=torch.int64)  # Very important to convert categorical data types into int date type.\n",
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Continuous Variables\n",
    "cont_feature = []\n",
    "\n",
    "for i in df.columns:\n",
    "    if i in ['MSSubClass', 'MSZoning','Street','LotShape']:\n",
    "        pass\n",
    "    else:\n",
    "        cont_feature.append(i)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LotFrontage', 'LotArea', '1stFlrSF', '2ndFlrSF', 'Total_Years']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   80., 11622.,   896.,     0.,    63.],\n",
       "        [   81., 14267.,  1329.,     0.,    66.],\n",
       "        [   74., 13830.,   928.,   701.,    27.],\n",
       "        ...,\n",
       "        [  160., 20000.,  1224.,     0.,    64.],\n",
       "        [   62., 10441.,   970.,     0.,    32.],\n",
       "        [   74.,  9627.,   996.,  1004.,    31.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Stacking Continuos Variables:\n",
    "cont_values = np.stack([df[i].values for i in cont_feature] , axis=1)\n",
    "cont_values = torch.tensor(cont_values , dtype=torch.float)\n",
    "cont_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_values.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1459 entries, 0 to 1458\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   MSSubClass   1459 non-null   int64  \n",
      " 1   MSZoning     1459 non-null   int64  \n",
      " 2   LotFrontage  1459 non-null   float64\n",
      " 3   LotArea      1459 non-null   int64  \n",
      " 4   Street       1459 non-null   int64  \n",
      " 5   LotShape     1459 non-null   int64  \n",
      " 6   1stFlrSF     1459 non-null   int64  \n",
      " 7   2ndFlrSF     1459 non-null   int64  \n",
      " 8   Total_Years  1459 non-null   int64  \n",
      "dtypes: float64(1), int64(8)\n",
      "memory usage: 102.7 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['MSSubClass'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding:\n",
    "#### Each categories are converted to their feature vector representation using Embedded Matrix whose dimension is:\n",
    "##### By thumb rule : min(50, (x+1)//2) for Categorical Data Conversion but not for NLP applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Embedding Size for Categorical Features:\n",
    "\n",
    "cat_dims = [(len(df[col].unique())) for col in ['MSSubClass', 'MSZoning','Street','LotShape']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16, 5, 2, 4]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Embedded Vector dimensions using thumb rule\n",
    "\n",
    "embedding_dims = [(x, min(50,(x+1)//2)) for x in cat_dims]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(16, 8), (5, 3), (2, 1), (4, 2)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATING ACTUAL EMBEDDING MATRIX: DOING WORD2VEC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Embedding(16, 8)\n",
       "  (1): Embedding(5, 3)\n",
       "  (2): Embedding(2, 1)\n",
       "  (3): Embedding(4, 2)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_representation = nn.ModuleList([nn.Embedding(inp,out) for inp,out in embedding_dims])\n",
    "embed_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 2, 1, 3],\n",
       "        [0, 3, 1, 0],\n",
       "        [5, 3, 1, 0],\n",
       "        [5, 3, 1, 0]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_featuresz = cat_features[:4]\n",
    "cat_featuresz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACTUAL EMBEDDING FUNCTION:\n",
    "\n",
    "pd.set_option('display.max_rows',500)\n",
    "embedding_val = []\n",
    "for i,e in enumerate(embed_representation):\n",
    "    embedding_val.append(e(cat_featuresz[:,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-1.3782, -0.2115,  0.5782,  1.2140,  0.3704,  1.0138, -0.3132, -1.0376],\n",
       "         [-1.3782, -0.2115,  0.5782,  1.2140,  0.3704,  1.0138, -0.3132, -1.0376],\n",
       "         [ 1.0092,  0.4834,  1.2568,  1.2497, -0.2854,  1.3782,  0.0434, -0.5304],\n",
       "         [ 1.0092,  0.4834,  1.2568,  1.2497, -0.2854,  1.3782,  0.0434, -0.5304]],\n",
       "        grad_fn=<EmbeddingBackward0>),\n",
       " tensor([[-3.3066,  0.0987, -1.3296],\n",
       "         [ 1.3363,  0.6125,  0.2039],\n",
       "         [ 1.3363,  0.6125,  0.2039],\n",
       "         [ 1.3363,  0.6125,  0.2039]], grad_fn=<EmbeddingBackward0>),\n",
       " tensor([[1.3975],\n",
       "         [1.3975],\n",
       "         [1.3975],\n",
       "         [1.3975]], grad_fn=<EmbeddingBackward0>),\n",
       " tensor([[ 0.1742, -1.1484],\n",
       "         [ 0.5836,  1.3188],\n",
       "         [ 0.5836,  1.3188],\n",
       "         [ 0.5836,  1.3188]], grad_fn=<EmbeddingBackward0>)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3782, -0.2115,  0.5782,  1.2140,  0.3704,  1.0138, -0.3132, -1.0376,\n",
       "         -3.3066,  0.0987, -1.3296,  1.3975,  0.1742, -1.1484],\n",
       "        [-1.3782, -0.2115,  0.5782,  1.2140,  0.3704,  1.0138, -0.3132, -1.0376,\n",
       "          1.3363,  0.6125,  0.2039,  1.3975,  0.5836,  1.3188],\n",
       "        [ 1.0092,  0.4834,  1.2568,  1.2497, -0.2854,  1.3782,  0.0434, -0.5304,\n",
       "          1.3363,  0.6125,  0.2039,  1.3975,  0.5836,  1.3188],\n",
       "        [ 1.0092,  0.4834,  1.2568,  1.2497, -0.2854,  1.3782,  0.0434, -0.5304,\n",
       "          1.3363,  0.6125,  0.2039,  1.3975,  0.5836,  1.3188]],\n",
       "       grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.cat(embedding_val,1)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Implement Dropout:\n",
    "dropout = nn.Dropout(.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0000, -0.3526,  0.0000,  2.0233,  0.6173,  0.0000, -0.5220, -1.7293,\n",
       "         -5.5110,  0.0000, -2.2161,  2.3292,  0.2904, -1.9140],\n",
       "        [-0.0000, -0.0000,  0.0000,  2.0233,  0.0000,  1.6896, -0.5220, -1.7293,\n",
       "          2.2272,  1.0209,  0.0000,  0.0000,  0.9727,  2.1981],\n",
       "        [ 1.6820,  0.0000,  0.0000,  2.0829, -0.0000,  2.2970,  0.0000, -0.8840,\n",
       "          0.0000,  1.0209,  0.3398,  2.3292,  0.0000,  2.1981],\n",
       "        [ 0.0000,  0.8057,  0.0000,  2.0829, -0.0000,  0.0000,  0.0723, -0.0000,\n",
       "          0.0000,  0.0000,  0.3398,  0.0000,  0.0000,  0.0000]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_embed = dropout(z)\n",
    "final_embed "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Neural Network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNN(nn.Module):\n",
    "    def __init__(self, embedding_dims,n_cont, out_sz, layers , p =0.5 ):\n",
    "        # embedding_dims : Dimensions of all the embedding layers to be performed\n",
    "        # n_cont: Number of features with continuos values\n",
    "        # out_sz : Number of Output features\n",
    "        # layers: list containing number of neurons in hidden layers\n",
    "        # p: dropout probability \n",
    "        super().__init__()\n",
    "        self.embds = nn.ModuleList([nn.Embedding(inp,out) for inp,out in embedding_dims])   # Discussed Earlier\n",
    "        self.emb_dropout = nn.Dropout(p) # To apply Dorpout\n",
    "        self.batch_norm_cont = nn.BatchNorm1d(n_cont)   # To apply Normalisation to Continuous Values since they are very large\n",
    "        \n",
    "        \n",
    "        layerlist = []\n",
    "        n_emb = sum((out for inp,out in embedding_dims))\n",
    "        n_in = n_emb + n_cont\n",
    "        # For the input size : n_in,\n",
    "        # n_cont : denotes number of continuos features\n",
    "        # n_emb: denotes total number of features we we get after performing embedding on categorical features\n",
    "            \n",
    "        for i in layers:\n",
    "            layerlist.append(nn.Linear(n_in,i))\n",
    "            layerlist.append(nn.ReLU(inplace=True))\n",
    "            layerlist.append(nn.BatchNorm1d(i))\n",
    "            layerlist.append(nn.Dropout(p))\n",
    "            n_in = i\n",
    "        layerlist.append(nn.Linear(layers[-1],out_sz))\n",
    "            \n",
    "            \n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "        # Initially layers was a list containing just list of number of neurons in the hidden layers , but now it is a complete module in itself.\n",
    "        # nn.Sequential() : stores multiple modules and run them in sequence. It takes as arguments all the modules it has to run in sequence, hence * before layerlist.\n",
    "        # *layerlist: unpacks all the list/tuple items because this is how Sequential() takes arguments.\n",
    "        \n",
    "    def forward(self, x_cat, x_cont):\n",
    "        embedding = []\n",
    "        for i,e in enumerate(self.embds):\n",
    "            embedding.append(e(x_cat[:,i]))\n",
    "        x = torch.cat(embedding,axis=1)\n",
    "        x = torch.cat([x,x_cont],axis = 1)\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cont_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model:\n",
    "\n",
    "torch.manual_seed(100)\n",
    "model = FeedForwardNN(embedding_dims,len(cont_feature),1,[100,50],p=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeedForwardNN(\n",
       "  (embds): ModuleList(\n",
       "    (0): Embedding(16, 8)\n",
       "    (1): Embedding(5, 3)\n",
       "    (2): Embedding(2, 1)\n",
       "    (3): Embedding(4, 2)\n",
       "  )\n",
       "  (emb_dropout): Dropout(p=0.4, inplace=False)\n",
       "  (batch_norm_cont): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=19, out_features=100, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.4, inplace=False)\n",
       "    (4): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.4, inplace=False)\n",
       "    (8): Linear(in_features=50, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Loss Function and Optimiser:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.MSELoss()     # Later on will be converted to RMSE by taking square root\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1459, 4]), torch.Size([1459, 5]))"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features.shape , cont_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Train-Test Split\n",
    "\n",
    "batch_size = 1200\n",
    "test_size = int(batch_size* 0.15)\n",
    "\n",
    "train_categorical_data = cat_features[:batch_size-test_size]\n",
    "test_categorical_data = cat_features[batch_size-test_size:batch_size]\n",
    "train_cont = cont_values[:batch_size-test_size]\n",
    "test_cont = cont_values[batch_size-test_size:batch_size]\n",
    "y_train = y[:batch_size-test_size]\n",
    "y_test = y[batch_size-test_size:batch_size] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1020, 4]),\n",
       " torch.Size([180, 4]),\n",
       " torch.Size([1020, 5]),\n",
       " torch.Size([180, 5]),\n",
       " torch.Size([1020, 1]),\n",
       " torch.Size([180, 1]))"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_categorical_data.shape , test_categorical_data.shape , train_cont.shape , test_cont.shape, y_train.shape , y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 , Loss: 200496.75\n",
      "Epoch: 100 , Loss: 200406.953125\n",
      "Epoch: 200 , Loss: 200063.453125\n",
      "Epoch: 300 , Loss: 199440.984375\n",
      "Epoch: 400 , Loss: 198579.734375\n",
      "Epoch: 500 , Loss: 197477.6875\n",
      "Epoch: 600 , Loss: 196023.4375\n",
      "Epoch: 700 , Loss: 194500.46875\n",
      "Epoch: 800 , Loss: 192843.578125\n",
      "Epoch: 900 , Loss: 190772.578125\n",
      "Epoch: 1000 , Loss: 188657.46875\n",
      "Epoch: 1100 , Loss: 186573.53125\n",
      "Epoch: 1200 , Loss: 184084.578125\n",
      "Epoch: 1300 , Loss: 181632.484375\n",
      "Epoch: 1400 , Loss: 178698.5625\n",
      "Epoch: 1500 , Loss: 176296.265625\n",
      "Epoch: 1600 , Loss: 172742.484375\n",
      "Epoch: 1700 , Loss: 169806.953125\n",
      "Epoch: 1800 , Loss: 166061.25\n",
      "Epoch: 1900 , Loss: 162884.65625\n",
      "Epoch: 2000 , Loss: 159704.078125\n",
      "Epoch: 2100 , Loss: 156229.734375\n",
      "Epoch: 2200 , Loss: 152257.34375\n",
      "Epoch: 2300 , Loss: 149225.0625\n",
      "Epoch: 2400 , Loss: 144578.296875\n",
      "Epoch: 2500 , Loss: 141433.828125\n",
      "Epoch: 2600 , Loss: 136675.09375\n",
      "Epoch: 2700 , Loss: 133089.703125\n",
      "Epoch: 2800 , Loss: 129864.1640625\n",
      "Epoch: 2900 , Loss: 126209.0546875\n",
      "Epoch: 3000 , Loss: 122477.1171875\n",
      "Epoch: 3100 , Loss: 118069.140625\n",
      "Epoch: 3200 , Loss: 116879.140625\n",
      "Epoch: 3300 , Loss: 112240.7890625\n",
      "Epoch: 3400 , Loss: 108854.3203125\n",
      "Epoch: 3500 , Loss: 105340.8828125\n",
      "Epoch: 3600 , Loss: 102572.1796875\n",
      "Epoch: 3700 , Loss: 99975.734375\n",
      "Epoch: 3800 , Loss: 97731.8515625\n",
      "Epoch: 3900 , Loss: 93902.03125\n",
      "Epoch: 4000 , Loss: 93895.2578125\n",
      "Epoch: 4100 , Loss: 90870.7265625\n",
      "Epoch: 4200 , Loss: 89119.828125\n",
      "Epoch: 4300 , Loss: 88706.28125\n",
      "Epoch: 4400 , Loss: 87576.59375\n",
      "Epoch: 4500 , Loss: 86701.0625\n",
      "Epoch: 4600 , Loss: 86346.953125\n",
      "Epoch: 4700 , Loss: 85475.5078125\n",
      "Epoch: 4800 , Loss: 84617.9296875\n",
      "Epoch: 4900 , Loss: 85318.953125\n"
     ]
    }
   ],
   "source": [
    "# Running the model:\n",
    "\n",
    "\n",
    "epochs = 5000\n",
    "final_losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    y_pred = model(train_categorical_data,train_cont)\n",
    "    loss = torch.sqrt(loss_function(y_pred,y_train))   # RMSE\n",
    "    final_losses.append(loss.detach().numpy())\n",
    "    if i%100==0:\n",
    "        print(\"Epoch: {} , Loss: {}\".format(i, loss.detach().numpy()))\n",
    "    \n",
    "    optimiser.zero_grad()\n",
    "    loss.backward()\n",
    "    optimiser.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'RMSE Loss')"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PLOTTING THE GRAPH:\n",
    "\n",
    "plt.plot(range(epochs), final_losses)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"RMSE Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1459, 5])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VALIDATE THE TEST DATA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred = model(cat_features,cont_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>117974.960938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>179942.078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>231062.718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>161685.765625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>144043.640625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>1455</td>\n",
       "      <td>219902.406250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>1456</td>\n",
       "      <td>165881.359375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>1457</td>\n",
       "      <td>152904.953125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>1458</td>\n",
       "      <td>186716.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>1459</td>\n",
       "      <td>141043.328125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1459 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id      SalePrice\n",
       "0        1  117974.960938\n",
       "1        2  179942.078125\n",
       "2        3  231062.718750\n",
       "3        4  161685.765625\n",
       "4        5  144043.640625\n",
       "...    ...            ...\n",
       "1454  1455  219902.406250\n",
       "1455  1456  165881.359375\n",
       "1456  1457  152904.953125\n",
       "1457  1458  186716.859375\n",
       "1458  1459  141043.328125\n",
       "\n",
       "[1459 rows x 2 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soln = pd.DataFrame(y_pred , columns=[\"SalePrice\"])\n",
    "soln = soln.reset_index()\n",
    "soln['index'] = soln['index']+1\n",
    "soln.rename(columns={'index':\"Id\"}, inplace=True)\n",
    "soln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soln.to_csv(\"Submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Id = pd.read_csv(\"test.csv\", usecols=[\"Id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soln = pd.concat(Id,soln, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading The saved Model:\n",
    "embs_size = [(15,8),(5,3),(2,1),(4,2)]\n",
    "model1 =FeedForwardNN(embs_size,len(cont_feature),1,[100,50],p=0.4)\n",
    "# Loading Model Weights:\n",
    "model1.load_state_dict(torch.load(\"HousePriceWithWeights.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeedForwardNN(\n",
       "  (embds): ModuleList(\n",
       "    (0): Embedding(15, 8)\n",
       "    (1): Embedding(5, 3)\n",
       "    (2): Embedding(2, 1)\n",
       "    (3): Embedding(4, 2)\n",
       "  )\n",
       "  (emb_dropout): Dropout(p=0.4, inplace=False)\n",
       "  (batch_norm_cont): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=19, out_features=100, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.4, inplace=False)\n",
       "    (4): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.4, inplace=False)\n",
       "    (8): Linear(in_features=50, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1459, 4]), torch.Size([1459, 5]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features.shape , cont_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 2\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcont_values\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[43], line 38\u001b[0m, in \u001b[0;36mFeedForwardNN.forward\u001b[0;34m(self, x_cat, x_cont)\u001b[0m\n\u001b[1;32m     36\u001b[0m embedding \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membds):\n\u001b[0;32m---> 38\u001b[0m     embedding\u001b[38;5;241m.\u001b[39mappend(\u001b[43me\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_cat\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     39\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(embedding,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     40\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([x,x_cont],axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/functional.py:2264\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2258\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2259\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2260\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2261\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2262\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2263\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2264\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred = model1(cat_features,cont_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
